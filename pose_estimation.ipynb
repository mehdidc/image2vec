{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "os.environ[\"THEANO_FLAGS\"] = \"device=gpu\"\n",
    "import theano\n",
    "from caffezoo.googlenet import GoogleNet\n",
    "from caffezoo.vgg import VGG\n",
    "from skimage.io import imread\n",
    "from skimage.transform import AffineTransform, resize, SimilarityTransform, warp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.base import clone\n",
    "from sklearn.manifold import TSNE, LocallyLinearEmbedding, Isomap\n",
    "from skimage.util import pad\n",
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "def predictability_score(model, X, y):\n",
    "    s = 0\n",
    "    y_hat = model.predict(X)\n",
    "    for i in range(y.shape[1]):\n",
    "        s += explained_variance_score(y[:, i], y_hat[:, i])\n",
    "    return s / y.shape[1]\n",
    "\n",
    "def predictability(model, X, Y, cv=5):\n",
    "    if len(X.shape) > 2:\n",
    "        X = X.reshape((X.shape[0], -1))\n",
    "    return cross_val_score(model, X, Y, predictability_score, cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from skimage.io import imread\n",
    "images_index = []\n",
    "images = []\n",
    "for filename in glob.glob(\"pose/lsp_dataset/images/*.jpg\"):\n",
    "    basename = os.path.basename(filename)\n",
    "    image_id = int(basename[2:6]) - 1\n",
    "    images.append(resize(imread(filename), (224, 224)))\n",
    "    images_index.append(image_id)\n",
    "\n",
    "images = np.array(images)\n",
    "images_index = np.array(images_index)\n",
    "\n",
    "from scipy.io import loadmat\n",
    "joints = loadmat(\"pose/lsp_dataset/joints.mat\")[\"joints\"]\n",
    "joints = joints.transpose((2, 0, 1))\n",
    "joints = joints.reshape((joints.shape[0], -1))\n",
    "joints = joints[images_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def concat(layers):\n",
    "    layers = [layer.reshape((layer.shape[0], np.prod(layer.shape[1:]))) for layer in layers]\n",
    "    return np.concatenate(layers, axis=1)\n",
    "\n",
    "def gram_matrix(x):\n",
    "    #x = x.flatten(ndim=3)\n",
    "    x = x.reshape((x.shape[0], x.shape[1], -1))\n",
    "    g = np.tensordot(x, x, axes=([2], [2]))\n",
    "    return g\n",
    "\n",
    "def reduce_dim(f, dropout=0.5, seed=1234):\n",
    "    def f_(layers):\n",
    "        rng = np.random.RandomState(seed)\n",
    "        layers = [\n",
    "            l[:, (rng.uniform(size=l.shape[1]) > dropout)] for l in layers\n",
    "        ]\n",
    "        return f(layers)\n",
    "    return f_\n",
    "def gram(layers):\n",
    "    layers = [\n",
    "        gram_matrix(layer) for layer in layers\n",
    "    ]\n",
    "    return concat(layers)\n",
    "def as_is(layers):\n",
    "    return layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "L = [ \"input\",\n",
    "      \"conv2/3x3_reduce\",\n",
    "     \"inception_3a/output\", \"inception_3b/output\", \n",
    "     \"inception_4a/output\", \"inception_4b/output\",\n",
    "     \"inception_4c/output\", \"inception_4d/output\",\n",
    "     \"inception_4e/output\", \"inception_5a/output\",\n",
    "     \"inception_5b/output\", \"inception_5b/output\", \"pool5/7x7_s1\"]\n",
    "layers = [L[5]]\n",
    "model = GoogleNet(resize=False, \n",
    "                  layer_names=layers, \n",
    "                  aggregate_function=as_is, \n",
    "                  batch_size=50)\n",
    "model._load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h = model.transform(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(h.shape)\n",
    "print(joints.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA, RandomizedPCA\n",
    "h_ = RandomizedPCA(n_components=100).fit_transform(h.reshape((h.shape[0], -1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictability(RandomForestRegressor(), h_ , joints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
